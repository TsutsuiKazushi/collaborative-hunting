{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "from common.network import DuelingNetwork\n",
    "from common.util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" speed \"\"\"\n",
    "speed = \"fast\" # \"slow\", \"equal\" or \"fast\"\n",
    "\n",
    "\"\"\" Epsilon \"\"\"\n",
    "epsilon = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/npyio.py:719: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  val = np.asanyarray(val)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "\"\"\" seed \"\"\"\n",
    "seeds = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "names = [\"self_play\"]\n",
    "\n",
    "for seed in seeds:\n",
    "\n",
    "    \"\"\" participant \"\"\"\n",
    "    for name in names:\n",
    "\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "\n",
    "        \"\"\" divice \"\"\"\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(device)\n",
    "\n",
    "        \"\"\" Network \"\"\"\n",
    "        net_p = DuelingNetwork(10, 13).to(device)\n",
    "        net_e = DuelingNetwork(10, 13).to(device)\n",
    "        \n",
    "        \"\"\" Environment \"\"\"\n",
    "        env_dir = os.path.join(os.pardir, \"c1ae\")\n",
    "        sys.path.append(env_dir)\n",
    "        from chase1_and_escape import Chase1AndEscape\n",
    "        \n",
    "        if speed == \"fast\":\n",
    "            speed_p = 3.6\n",
    "        elif speed == \"equal\":\n",
    "            speed_p = 3.0\n",
    "        elif speed == \"slow\":\n",
    "            speed_p = 2.4\n",
    "        \n",
    "        speed_e = 3\n",
    "        max_step_episode = 300\n",
    "        env = Chase1AndEscape(speed_pursuer=speed_p, speed_evader=speed_e, max_step=max_step_episode)\n",
    "\n",
    "        \"\"\" Load \"\"\"\n",
    "        net_p.load_state_dict(torch.load(\"../model/c1ae/p_\" + str (speed_p) + \".pth\"))\n",
    "        net_e.load_state_dict(torch.load(\"../model/c1ae/e_\" + str (speed_p) + \".pth\"))\n",
    "\n",
    "        \"\"\" No. of episodes \"\"\"\n",
    "        num_episodes_test = 100\n",
    "\n",
    "        \"\"\" Simulation \"\"\"\n",
    "        rep_v_list = []\n",
    "        rep_a_list = []\n",
    "        q_list = []\n",
    "        pos_list = []\n",
    "\n",
    "        for i in range(num_episodes_test):\n",
    "\n",
    "            pursuer_rep_v_episode = []\n",
    "            evader_rep_v_episode = []\n",
    "            pursuer_rep_a_episode = []\n",
    "            evader_rep_a_episode = []\n",
    "            pursuer_q_episode = []\n",
    "            evader_q_episode = []\n",
    "            pursuer_pos_episode = []\n",
    "            evader_pos_episode = []\n",
    "\n",
    "            obs_p, obs_e = env.reset()\n",
    "            obs_p, obs_e = torch.Tensor(obs_p), torch.Tensor(obs_e)\n",
    "            done = False\n",
    "            step_episode = 0\n",
    "\n",
    "            while not done:\n",
    "\n",
    "                feature_p = net_p.forward_com(obs_p.float().to(device))\n",
    "                feature_v_p = torch.relu(torch.matmul(feature_p, net_p.fc_state[0].weight.T) + net_p.fc_state[0].bias)\n",
    "                feature_a_p = torch.relu(torch.matmul(feature_p, net_p.fc_advantage[0].weight.T) + net_p.fc_advantage[0].bias)\n",
    "\n",
    "                feature_e = net_e.forward_com(obs_e.float().to(device))\n",
    "                feature_v_e = torch.relu(torch.matmul(feature_e, net_e.fc_state[0].weight.T) + net_e.fc_state[0].bias)\n",
    "                feature_a_e = torch.relu(torch.matmul(feature_e, net_e.fc_advantage[0].weight.T) + net_e.fc_advantage[0].bias)\n",
    "\n",
    "                q_p = net_p.forward(obs_p.float().to(device))\n",
    "                q_e = net_e.forward(obs_e.float().to(device))\n",
    "\n",
    "                action_p = net_p.act(obs_p.float().to(device), epsilon)\n",
    "                action_e = net_e.act(obs_e.float().to(device), epsilon)\n",
    "\n",
    "                next_obs_p, next_obs_e, reward_p, reward_e, done = env.step(action_p, action_e, step_episode)\n",
    "                next_obs_p, next_obs_e = torch.Tensor(next_obs_p), torch.Tensor(next_obs_e)        \n",
    "\n",
    "                obs_p = next_obs_p\n",
    "                obs_e = next_obs_e                \n",
    "                step_episode += 1\n",
    "\n",
    "                pos_p = env.pos_p\n",
    "                pos_e = env.pos_e\n",
    "\n",
    "                dist = get_dist(np.array(pos_p), np.array(pos_e))\n",
    "\n",
    "                pursuer_rep_v_episode.append(np.array(feature_v_p.detach().numpy()))\n",
    "                pursuer_rep_a_episode.append(np.array(feature_a_p.detach().numpy()))\n",
    "                evader_rep_v_episode.append(np.array(feature_v_e.detach().numpy()))\n",
    "                evader_rep_a_episode.append(np.array(feature_a_e.detach().numpy()))\n",
    "                pursuer_q_episode.append(np.array(q_p.detach().numpy()))\n",
    "                evader_q_episode.append(np.array(q_e.detach().numpy()))\n",
    "                pursuer_pos_episode.append(np.array(pos_p))\n",
    "                evader_pos_episode.append(np.array(pos_e))\n",
    "\n",
    "            rep_v_episode = []\n",
    "            rep_v_episode.append(evader_rep_v_episode)\n",
    "            rep_v_episode.append(pursuer_rep_v_episode)\n",
    "            rep_v_list.append(rep_v_episode)\n",
    "\n",
    "            rep_a_episode = []\n",
    "            rep_a_episode.append(evader_rep_a_episode)\n",
    "            rep_a_episode.append(pursuer_rep_a_episode)\n",
    "            rep_a_list.append(rep_a_episode)\n",
    "            \n",
    "            q_episode = []\n",
    "            q_episode.append(evader_q_episode)\n",
    "            q_episode.append(pursuer_q_episode)   \n",
    "            q_list.append(q_episode)\n",
    "\n",
    "            pos_episode = []\n",
    "            pos_episode.append(evader_pos_episode)\n",
    "            pos_episode.append(pursuer_pos_episode)\n",
    "            pos_list.append(pos_episode)\n",
    "            \n",
    "        \"\"\" Save \"\"\"\n",
    "        save_dir = \"self_play_results\"\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "        if epsilon==0:\n",
    "            name_policy = \"greedy\"\n",
    "        else:\n",
    "            name_policy = \"epsilon_greedy\"        \n",
    "        \n",
    "        file_path = os.path.join(save_dir, \"results_1on1_\" + name + \"_\" +  speed + \"_\" + name_policy + \"_seed_\" + str(seed) + \".npz\")\n",
    "        np.savez(file_path, pos=pos_list, q=q_list, rep_v=rep_v_list, rep_a=rep_a_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
